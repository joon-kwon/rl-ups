{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138b94a0",
   "metadata": {},
   "source": [
    "Les parties I et III ne comportent que de la programmation. \n",
    "\n",
    "La partie II ne comporte que des questions théoriques, **à rédiger sur une copie**.\n",
    "\n",
    "La partie I est indépendante des deux autres. La seconde question de la partie III fait appel à la partie II.\n",
    "\n",
    "Il n'est pas nécessaire de traiter l'ensemble du sujet pour obtenir une bonne note.\n",
    "\n",
    "Penser à régulièrement enregistrer le notebook.\n",
    "\n",
    "Le notebook devra être envoyé par e-mail à l'adresse joon.kwon@inrae.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eeb042",
   "metadata": {},
   "source": [
    "# Partie I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9337c26",
   "metadata": {},
   "source": [
    "On reprend le problème du plus grand nombre à 5 chiffres (cf. TD1, TP1, TP2), à ceci près que les chiffres sont ici tirées selon une distribution $\\nu$ fixée mais inconnue, et que le choix d'un emplacement déjà pris est sanctionné par un paiement de -100000.\n",
    "\n",
    "Le but de l'agent est de former un nombre à 5 chiffres, le plus grand possible. On considère 5 emplacements, initialement vides, correspondant aux chiffre des unités, des dizaines, des centaines, des milliers, et des dizaines de milliers. À chaque étape, un chiffre (entre 0 et 9) est tiré selon $\\nu$ et présenté à l'agent. Celui-ci doit le placer dans l'un des emplacements disponibles. Le nombre est donc formé au bout de 5 étapes.\n",
    "\n",
    "On modélise le problème par un MDP dont\n",
    "- l'espace d'états est $\\mathcal{S}=\\left\\{ 0,1 \\right\\}^5\\times \\left\\{ 0,\\dots,9 \\right\\}$ où pour les cinq premières composantes, un 1 correspond à un emplacement libre,\n",
    "- l'ensemble de paiements est $\\mathcal{R}=\\left\\{ 0,1,\\dots,99999 \\right\\}$,\n",
    "- l'ensemble d'actions est $\\mathcal{A}=\\left\\{ 1,\\dots,5 \\right\\}$,\n",
    "- la dynamique de transition est \n",
    "$$p(\\,\\cdot\\,|s,a)= \\begin{cases} \\delta_{-100000}\\otimes \\delta_s&\\text{si $s^{(a)}=0$}\\\\ \n",
    "\\delta_{10^{a-1}s^{(6)}} \\otimes \\delta_{\\sigma(s,a)}\\otimes\n",
    "\\nu&\\text{si $s^{(a)}=1$}.\n",
    "\\end{cases}$$\n",
    "\n",
    "On considère un paiement non-escompté ($\\gamma=1$) et une distribution pour l'état initial $\\mu=\\delta_{(1,1,1,1,1)}\\otimes \\nu$.\n",
    "\n",
    "L'implémentation de l'environnement ci-dessous reprend les conventions de la librairie Gymnasium. L'épisode est signalé comme terminé lorsque les 5 emplacements sont occupés (lorsque le nombre est formé) et comme tronqué au bout de 500 étapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class nombre_cinq_chiffres():\n",
    "    def __init__(self):\n",
    "        np.random.seed(2025)\n",
    "        x = np.random.uniform(low=0.0, high=2, size=10)\n",
    "        exp_x = np.exp(x - np.max(x))\n",
    "        self.d = exp_x / exp_x.sum()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def reset(self):\n",
    "        self.s = (1,1,1,1,1, np.random.choice(a=10, p=self.d))\n",
    "        self.t = 0\n",
    "        return self.s, None\n",
    "    \n",
    "    def step(self, a):\n",
    "        number = list(self.s[:5])\n",
    "        number[a-1] = 0\n",
    "\n",
    "        if self.s[a-1] == 1:\n",
    "            r = (10**(a-1))*self.s[5]\n",
    "            self.s = (*number,np.random.choice(a=10, p=self.d))\n",
    "        else:\n",
    "            r = -100000\n",
    "\n",
    "        terminated = (number == [0,0,0,0,0])\n",
    "\n",
    "        self.t += 1\n",
    "        truncated = (self.t == 500)\n",
    "\n",
    "        return self.s, r, terminated, truncated, None\n",
    "\n",
    "env =  nombre_cinq_chiffres()\n",
    "\n",
    "# liste contenant tous les états\n",
    "S = [(i1,i2,i3,i4,i5,i6) for i1 in [0,1] for i2 in [0,1] for i3 in [0,1] for i4 in [0,1] for i5 in [0,1] for i6 in range(10)]\n",
    "\n",
    "# liste contenant tous les couples (état,action)\n",
    "SA = [(s,a) for s in S for a in [1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bbb96",
   "metadata": {},
   "source": [
    "**Question 1**: Implémenter un algorithme d'apprentissage par renforcement (pour le controle). Le faire tourner pendant (au moins) 10000 épisodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421179b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "eps = .2\n",
    "n_episodes = 10000\n",
    "\n",
    "# initialisation \n",
    "q_cumul, n_updates = dict(), dict()\n",
    "for sa in SA:\n",
    "    q_cumul[sa] = 0.\n",
    "    n_updates[sa] = 0\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    s = env.reset()[0]\n",
    "\n",
    "    terminated, truncated = False, False\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        # compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40234015",
   "metadata": {},
   "source": [
    "**Question 2**: Afficher la politique $\\pi$ obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff83806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "033c6bac",
   "metadata": {},
   "source": [
    "**Question 3**: Estimer la quantité suivante en utilisant la politique obtenue $\\pi$ sur 10000 épisodes.\n",
    "$$\\mathbb{E}_{\\mu,\\pi}\\left[ \\sum_{t=1}^{+\\infty}R_t\\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c4508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f0df238",
   "metadata": {},
   "source": [
    "# Partie II (à rédiger sur une copie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b90930",
   "metadata": {},
   "source": [
    "On considère le cadre et les notation du cours, avec un MDP donné.\n",
    "Soit $\\gamma\\in (0,1)$ fixé et $\\pi$ une politique stationnaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd7c44",
   "metadata": {},
   "source": [
    "**Question 1**: Soit $N\\geqslant 1$ et $\\mu_1,\\dots,\\mu_N\\geqslant 0$ tels que\n",
    "$\\sum_{n=1}^N\\mu_n=1$.\n",
    "On considère l'opérateur $\\tilde{B}_{\\pi}=\\sum_{n=1}^N\\mu_n(B_{\\pi}^{(Q)})^n$ (où $(B_{\\pi}^{(Q)})^n$ désigne\n",
    "l'opérateur $B_{\\pi}^{(Q)}$ itéré $n$ fois)\n",
    "\n",
    "**a)** Montrer que $\\tilde{B}_\\pi$ est $\\gamma$-lipschitzienne pour $\\left\\|\\,\\cdot\\,\\right\\|_{\\infty}$.\n",
    "\n",
    "**b)** Déterminer les points fixes de $\\tilde{B}_{\\pi}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cc878",
   "metadata": {},
   "source": [
    "**Question 2**: Soit $0\\leqslant \\lambda<1$. On définit l'opérateur\n",
    "$B_{\\pi}^{\\left[ \\lambda \\right] }$ par\n",
    "$$B_{\\pi}^{\\left[ \\lambda \\right] }q=(1-\\lambda)\\sum_{n=0}^{+\\infty}\\lambda^{n-1}B_{\\pi}^nq,\\quad q\\in \\mathbb{R}^{\\mathcal{S}\\times \\mathcal{A}}.$$\n",
    "\n",
    "**a)** Montrer que $B_{\\pi}^{\\left[ \\lambda \\right] }$ est bien définie\n",
    "et $\\gamma$-lipschitzienne pour $\\left\\|\\,\\cdot\\,\\right\\|_{\\infty}$.\n",
    "\n",
    "**b)**Déterminer les points fixes de cet opérateur.\n",
    "\n",
    "**c)** Soit $q\\in \\mathbb{R}^{\\mathcal{S}\\times \\mathcal{A}}$. Déterminer\n",
    "la limite de $B_{\\pi}^{\\left[ \\lambda \\right] }q$ quand $\\lambda\\to 1^-$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f1944",
   "metadata": {},
   "source": [
    "**Question 3**: Soit $q\\in \\mathbb{R}^{\\mathcal{S}\\times \\mathcal{A}}$, $s\\in\n",
    "\\mathcal{S}, a\\in \\mathcal{A}$ et \n",
    "$(S_0,A_0,R_1,S_1,A_1,R_2,\\dots )$ une histoire infinie aléatoire\n",
    "de loi $\\mathbb{P}_{s,a,\\pi}$.\n",
    "\n",
    "**a)** Pour $n\\geqslant 1$, rappeler l'estimateur stochastique de\n",
    "$(B_{\\pi}^nq)(s,a)$ vu en cours.\n",
    "\n",
    "**b)** En déduire un estimateur stochastique pour $(B_{\\pi}^{\\left[ \\lambda \\right] }q)(s,a)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df280c1d",
   "metadata": {},
   "source": [
    "**Question 4**: Proposer un algorithme d'évaluation de politique (en programmation\n",
    "dynamique) faisant appel à l'opérateur $B_{\\pi}^{\\left[ \\lambda\n",
    "\\right] }$, et établir sa convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfeed2a",
   "metadata": {},
   "source": [
    "**Question 5**: Proposer un algorithme de contrôle (en apprentissage par renforcement) faisant appel à l'estimateur obtenu à la question **3b** et à des politiques $\\varepsilon$-gloutonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206247a",
   "metadata": {},
   "source": [
    "**Question 6**: Soit $p\\geqslant 1$ et $\\left\\{ q_w \\right\\}_{w\\in \\mathbb{R}^p}$ un sous-ensemble de $\\mathbb{R}^{\\mathcal{S}\\times \\mathcal{A}}$ telle que $w\\mapsto q_w$ est différentiable. Proposer un algorithme d'apprentissage par renforcement de type semi-gradient faisant appel à la famille paramétrique $\\left\\{ q_w \\right\\}_{w\\in \\mathbb{R}^p}$, à l'estimateur de la question 3b, ainsi qu'à des politiques $\\varepsilon$-gloutonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4adc7",
   "metadata": {},
   "source": [
    "# Partie III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa474f6",
   "metadata": {},
   "source": [
    "Soit $p\\geqslant 1$, $\\left\\{ q_w \\right\\}_{w\\in \\mathbb{R}^p}$ un sous-ensemble de $\\mathbb{R}^{\\mathcal{S}\\times \\mathcal{A}}$ telle que $w\\mapsto q_w$ est différentiable, et $0\\leqslant \\lambda<1$. On définit l'algorithme de type semi-gradient suivant.\n",
    "\n",
    "**Input**: number of episodes $N\\geqslant 1$.\n",
    "\n",
    "$w\\leftarrow 0\\in \\mathbb{R}^p$\n",
    "\n",
    "$z\\leftarrow 0\\in \\mathbb{R}^p$\n",
    "\n",
    "**for** $n=1,\\dots,N$ **do**\n",
    "> Observe $S_0$\n",
    ">\n",
    "> Choose $A_0$\n",
    ">\n",
    "> $t\\leftarrow 0$  \n",
    "> **while** episode is not terminated nor truncated **do**\n",
    ">> Observe $R_{t+1},S_{t+1}$        \n",
    ">> $A_{t+1}\\sim \\pi_{g,\\varepsilon}\\left[ q_w \\right](S_{t+1}) $        \n",
    ">> $\\delta\\leftarrow R_{t+1}+\\gamma q_w(S_{t+1},A_{t+1})-q_w(S_t,A_t)$     \n",
    ">> $z\\leftarrow \\gamma\\lambda z+\\nabla_wq_w(S_t,A_t)$        \n",
    ">> Choose $\\alpha$     \n",
    ">> $w\\leftarrow w+\\alpha\\delta z$        \n",
    ">> $t\\leftarrow t+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681dd70a",
   "metadata": {},
   "source": [
    "**Question 1**: En s'inspirant de la correction du TP6 (https://joon-kwon.github.io/rl-ups/TP6-correction.ipynb), implémenter l'algorithme ci-dessus pour résoudre le problème Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e8596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9802d935",
   "metadata": {},
   "source": [
    "**Question 2**: Implémenter également l'algorithme obtenu à la question 6) de la Partie II et comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b2f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
