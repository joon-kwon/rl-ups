{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58509ce-b4dd-4539-b25e-e4149cac4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pylab as pl\n",
    "from matplotlib.colors import ListedColormap\n",
    "np.set_printoptions(precision=3)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb472f",
   "metadata": {},
   "source": [
    "# Exercice 1 - Labyrinthe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f770f-8815-4416-8159-8b539cbdf67b",
   "metadata": {},
   "source": [
    "On considère le problème du labyrinthe abordé dans le premier TD.\n",
    "On modélise le problème par:\n",
    "- un ensemble d'états $\\mathcal{S}=\\left\\{ 1,\\dots,n \\right\\}\\times\n",
    "  \\left\\{ 1,\\dots,m \\right\\}$ qui correspond aux cellules,\n",
    "- un ensemble d'actions $\\mathcal{A}=\\left\\{ 0,1,2,3 \\right\\}$ qui correspondent respectivement à \"bas\", \"droite\", \"haut\", \"gauche\", et dont on utilisera parfois la représentation sous forme de vecteur,\n",
    "- un ensemble de gains $\\mathcal{R}=\\left\\{ 0,1 \\right\\}$\n",
    "- un ensemble d'états appelés \"murs intérieurs\" $\\mathcal{W}\\subset \\mathcal{A}$.\n",
    "\n",
    "Les transitions sont toutes déterministes, et sont telles qu'on obtient un gain de 1 lorsqu'on se déplace vers la cellule d'arrivée depuis une cellule voisine, et un gain de 0 sinon. Si l'action choisie correspond à un déplacement non-autorisé (soit qu'il mène à l'extérieur du labyrinthe, soit qu'il mène vers un mur intérieur, soit que l'état actual est un mur intérieur), l'état reste inchangé.\n",
    "\n",
    "On travaillera avec une valeur $\\gamma=.9$ fixée.\n",
    "\n",
    "La fonction suivante servira à représenter graphiquement le labyrinthe, les politiques, ainsi que les chemins empruntés par les politiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6969e732-67e9-4837-ab65-87e00c1f5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(policy=None, path=False):\n",
    "    grid_size = maze.shape\n",
    "    fig, ax = plt.subplots(figsize=(grid_size[1]+1, grid_size[0]+1))\n",
    "    im = ax.imshow(maze, cmap='Greys', interpolation='nearest', extent=[0, grid_size[1], 0, grid_size[0]], alpha=1)\n",
    "    ax.set_xticks(np.arange(0, grid_size[1]+1, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(0, grid_size[0]+1, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color='black', linestyle='-', linewidth=1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if policy is not None:\n",
    "        # Plot arrows\n",
    "        for i in range(grid_size[0]):\n",
    "            for j in range(grid_size[1]):\n",
    "                action = policy[i, j]\n",
    "                ax.text(j + 0.5, grid_size[0] - i - 0.5, action_arrows[action],\n",
    "                        ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "        if path is True:\n",
    "            cmap = pl.cm.Reds\n",
    "            my_cmap = cmap(np.arange(cmap.N))\n",
    "            my_cmap[:,-1] = np.linspace(0, 1, cmap.N)\n",
    "            my_cmap = ListedColormap(my_cmap)\n",
    "\n",
    "            im = ax.imshow(path_array(policy), cmap=my_cmap, interpolation='nearest', extent=[0, grid_size[1], 0, grid_size[0]], alpha=.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa85de-7a3b-4d9e-8b21-768646c4db45",
   "metadata": {},
   "source": [
    "Le code suivant construit un labyrinthe aléatoire de taille 30 x 30, avec des murs intérieurs qui ne sont pas tirés de façon indépendante. La case de départ est (0,0) (celle en haut à gauche), et la case d'arrivée est (29,29) (celle en bas à droite). Il est fait en sorte que ces deux cases ne soient pas murées. Les paramètres peuvent bien sûr être modifiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fd36e-aba2-4fdb-8f6e-4e70ed1d6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 30\n",
    "height = 30\n",
    "maze_size = (height, width) # nb lines & nb rows\n",
    "start_cell = (0,0)\n",
    "target_cell = (height-1, width-1)\n",
    "\n",
    "maze = np.random.binomial(1, p=.15, size=maze_size)\n",
    "maze[:round(2*width/3),round(height/4)] = 1\n",
    "maze[round(width/3):,round(3*height/4)] = 1\n",
    "chl = round(2*height/5)\n",
    "chu = round(3*height/5)\n",
    "cwl = round(2*width/5)\n",
    "cwu = round(3*width/5)\n",
    "maze[chl:chu,cwl:cwu] = np.random.binomial(1, p=.5, size=(chu-chl, cwu-cwl))\n",
    "maze[start_cell] = 0\n",
    "maze[target_cell] = 0\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17115d8d-e545-421d-9ecb-9e4938f03de2",
   "metadata": {},
   "source": [
    "*Attention* : vérifier visuellement que le labyrinthe ainsi obtenu possède un chemin allant de la case de départ à la case d'arriver. Dans le cas contraire, relancer le code ci-dessus afin de générer un autre labyrinthe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2b73c3-efcb-403b-a639-03b2a9791c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [0,1,2,3]\n",
    "action_coordinates = {0: np.array([1,0]),# down\n",
    "                      1: np.array([0,1]), # right\n",
    "                      2: np.array([-1,0]), # up\n",
    "                      3: np.array([0,-1])} # left\n",
    "action_arrows = ['↓', '→', '↑', '←']\n",
    "gamma = .9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0874260-e847-417d-83ef-e4081eb78b12",
   "metadata": {},
   "source": [
    "On ne va travailler qu'avec des politiques stationnaires déterministes $\\pi:\\mathcal{S}\\to \\mathcal{A}$. On va les représenter par des arrays de taille $n\\times m$ à valeurs dans $\\left\\{ 0,1,2,3 \\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b7463-18a5-4c92-91f5-3324498b5536",
   "metadata": {},
   "source": [
    "*Question 1*: Compléter la fonction suivante qui prend en entrée un état (un couple de la forme (i,j)) et une action (un entier parmi 0,1,2,3), et qui renvoie r, s_, qui sont respectivement le gain et le nouvel état. On pourra utiliser la fonction `tuple` qui convertit en n-uplet un objet d'un autre type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b03f206-c312-4722-9652-64c3580129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transision(s,a):\n",
    "    # Compléter\n",
    "    return r, s_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fea91b-32cf-47e8-8ddf-064287b7731d",
   "metadata": {},
   "source": [
    "*Question 2*: Compléter les fonctions suivantes qui calculent l'image d'une fonction état-valeur par les opérateurs de Bellman $B_{\\pi}^{(V)}$ et $B_*^{(V)}$. Une fonction état-valeur sera représentée par un array de taille $n\\times m$, et une politique (qu'on suppose donc stationnaire et déterministe), par un array de taille $n\\times m$ à valeurs dans $\\left\\{ 0,1,2,3 \\right\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d610a4bf-7f71-4961-9251-c7c205223d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_pi(v, pi): \n",
    "    # Compléter\n",
    "    return v_\n",
    "\n",
    "def B_star(v): \n",
    "    # Compléter\n",
    "    return v_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590143a-d905-4908-b9ed-1d1cf75a274c",
   "metadata": {},
   "source": [
    "*Question 3*: Compléter la fonction suivante qui renvoie une politique gloutonne par rapport à une fonction état-valeur donnée en entrée. On pourra utiliser la fonction np.argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a03e3f-cfd2-4f4e-9261-71b16a23f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(v): \n",
    "    # Compléter\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff34e1b-d29f-4d27-b684-5feedce785c1",
   "metadata": {},
   "source": [
    "*Question 4*: Compléter la fonction suivante qui renvoie le chemin suivi par la politique donnée en argument depuis la cellule de départ. On considère qu'un chemin se termine lorsque qu'une transition donne une cellule déjà visitée par le chemin. Le chemin sera donné sous la forme d'un array de taille $n\\times m$ à valeurs dans {0,1}, où 1 correspond aux cellules visitées par le chemin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc24159-f862-43c0-80ac-c823856e7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_array(policy):\n",
    "    # Compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffe906-5429-49da-9c24-0f5e634418b2",
   "metadata": {},
   "source": [
    "Le code suivant donne une fonction état-valeur aléatoire, qui servira de point de départ pour une itération valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3e259c4-571a-46d3-9c1c-29077da17f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.random.random(maze.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33b236-528e-43f0-8bcb-f9130f631130",
   "metadata": {},
   "source": [
    "*Question 5*: Calculer 50 itérations d'une itération valeur. Observer alors le chemin donné par la politique gloutonne grâce à la fonction plot appelée avec l'option path=True. Un chemin de longeur minimale a-t-il été trouvé ? Si besoin, calculer 50 itérations supplémentaires en relançant la cellule de code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2b298-2c6f-4fff-aa5c-17f58a6c02d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f516778-a4a6-4259-b432-2615c08a58a4",
   "metadata": {},
   "source": [
    "*Question 6*: Recommencer l'itération valeur, et s'arrêter lorsque la politique gloutonne reste inchangée pendant un certain nombre d'itérations (par exemple 100). A quelle itération cette politique a-t-elle été atteinte ? Combien de fois la fonction `transition` a-t-elle été appelée jusqu'à cette itération ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d623c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc8deb1e-8ba6-45bf-bc55-4be9f2bb7e29",
   "metadata": {},
   "source": [
    "*Question 7*: Implémenter une itération de politique, où pour chaque politique $\\pi$ considérée, $v_{\\pi}$ est approximée par 5 itérations de $B_{\\pi}$. Combien de fois la fonction `transition` a-t-elle été appelée jusqu'à ce que la politique obtenue semble avoir convergé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7e4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc2d21d",
   "metadata": {},
   "source": [
    "# Exercice 2 - Le plus grand nombre à 5 chiffres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b88aee",
   "metadata": {},
   "source": [
    "On considère à nouveau le problème rencontré dans le TD/TP 1. Le but de l'agent est de former un nombre à 5 chiffres, le plus grand possible. On considère 5 emplacements, initialement vides, correspondant aux chiffre des unités, des dizaines, des centaines, des milliers, et des dizaines de milliers. À chaque étape, un chiffre (entre 0 et 9) est tiré uniformément et présenté à l'agent. Celui-ci doit le placer dans l'un des emplacements disponibles. Le nombre est donc formé au bout de 5 étapes.\n",
    "\n",
    "On modélise le problème par un MDP dont\n",
    "- l'espace d'états est $\\mathcal{S}=\\left\\{ 0,1 \\right\\}^5\\times \\left\\{ 0,\\dots,9 \\right\\}$ où pour les cinq premières composantes, un 1 correspond à un emplacement libre,\n",
    "- l'ensemble de paiements est $\\mathcal{R}=\\left\\{ 0,1,\\dots,99999 \\right\\}$,\n",
    "- l'ensemble d'actions est $\\mathcal{A}=\\left\\{ 1,\\dots,5 \\right\\}$,\n",
    "- la dynamique de transition est \n",
    "$$p(\\,\\cdot\\,|s,a)= \\begin{cases} \\delta_0\\otimes \\delta_s&\\text{si $s^{(a)}=0$}\\\\ \n",
    "\\delta_{10^{a-1}s^{(6)}} \\otimes \\delta_{\\sigma(s,a)}\\otimes\n",
    "\\mathcal{U}(\\left\\{ 1,\\dots,9 \\right\\})&\\text{si $s^{(a)}=1$}.\n",
    "\\end{cases}$$\n",
    "\n",
    "On considère un paiement non-escompté ($\\gamma=1$, même si cela ne rentre pas strictement dans le cadre théorique du cours) et une distribution pour l'état initial $\\mu=\\delta_{(1,1,1,1,1)}\\otimes \\mathcal{U}(\\left\\{ 1,\\dots,9 \\right\\})$.\n",
    "\n",
    "**Question** En utilisant une itération valeur (resp. une itération de politique), déterminer une politique optimale $\\pi^*$, ainsi que le paiement associé\n",
    "$$\\mathbb{E}_{\\mu,\\pi^*}\\left[ \\sum_{t=1}^{+\\infty}R_t\\right].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c2b839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_initial_state():\n",
    "    return [1,1,1,1,1, random.randint(0,9)]\n",
    "\n",
    "def sigma(s,a):\n",
    "    number = s[:5]\n",
    "    number[a-1] = 0\n",
    "    return number\n",
    "\n",
    "def transition(s,a):\n",
    "    if s[a-1] == 1:\n",
    "        return (10**(a-1))*s[5], [*sigma(s,a),random.randint(0,9)]\n",
    "    else:\n",
    "        return 0, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7355b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "name": "3-TP.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
